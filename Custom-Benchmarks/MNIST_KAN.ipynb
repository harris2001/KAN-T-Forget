{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a1d7c2-e8bd-43c3-8849-24fadafcabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "# os.chdir(\"../../pykan/kan/\")\n",
    "from Scaled_KAN import *\n",
    "\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size_train = 32\n",
    "batch_size_test = 32\n",
    "lr = 1e-3\n",
    "momentum = 0.8\n",
    "\n",
    "tasks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e533f2-fba9-4be9-a4e6-2484cbde2e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional model: NN(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "KAN model: FastKAN(\n",
      "  (layers): ModuleList(\n",
      "    (0): FastKANLayer(\n",
      "      (layernorm): LayerNorm((784,), eps=1e-05, elementwise_affine=True)\n",
      "      (rbf): RadialBasisFunction()\n",
      "      (spline_linear): SplineLinear(in_features=6272, out_features=64, bias=False)\n",
      "      (base_linear): Linear(in_features=784, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): FastKANLayer(\n",
      "      (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (rbf): RadialBasisFunction()\n",
      "      (spline_linear): SplineLinear(in_features=512, out_features=10, bias=False)\n",
      "      (base_linear): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create conventional MLP model\n",
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        # 28*28 input image, 64 output units, 10 output units\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the image\n",
    "        x = x.view(-1, 28*28)\n",
    "        # Pass through the first layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Pass through the second layer\n",
    "        x = self.fc2(x)\n",
    "        # Apply log softmax\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = NN()\n",
    "model.to(device)\n",
    "print(f\"Conventional model: {model}\")\n",
    "\n",
    "# Create KAN model\n",
    "KAN_model = FastKAN(layers_hidden=[28*28,64,10], grid_min=3, grid_max=5, device=device)\n",
    "KAN_model.to(device)\n",
    "\n",
    "print(f\"KAN model: {KAN_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3ec13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = KAN_model\n",
    "# Transform the MNIST dataset to a tensor and normalising it\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.1307),(0.3081)), # Normalise samples using the mean of 0.1307 and std of 0.3081 - extracted after manual analysis\n",
    "    T.Lambda(lambda x: torch.flatten(x))\n",
    "])\n",
    "train_set = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=momentum)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Pair numbers together and create 5 tasks\n",
    "tasks = [(i,i+1) for i in range(0,10,2)]\n",
    "\n",
    "# For training: fill splitted_train array with examples where the target value is in task i\n",
    "targets = train_set.targets.numpy()\n",
    "splitted_train = []\n",
    "for task in tasks:\n",
    "    indices = np.where(np.isin(targets, task))[0]\n",
    "    subset = [train_set[i] for i in indices]\n",
    "    splitted_train.append(subset)\n",
    "\n",
    "# For testing: fill splitted_train array with examples where the target value is in task i\n",
    "targets = test_set.targets.numpy()\n",
    "splitted_test = []\n",
    "for task in tasks:\n",
    "    indices = np.where(np.isin(targets, task))[0]\n",
    "    subset = [test_set[i] for i in indices]\n",
    "    splitted_test.append(subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30fce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise a random image to check if the data is loaded correctly\n",
    "rand_image = random.choice(splitted_train[4])\n",
    "print(rand_image[0].shape)\n",
    "plt.imshow(rand_image[0].numpy().reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e69be73-93da-4577-99f1-53ba1a5976f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 0\n",
      "12665 2115\n",
      "Epoch 1 train/test accuracy: 1.00/1.00\n",
      "Epoch 2 train/test accuracy: 1.00/1.00\n",
      "Epoch 3 train/test accuracy: 1.00/1.00\n",
      "Epoch 4 train/test accuracy: 1.00/1.00\n",
      "Epoch 5 train/test accuracy: 1.00/1.00\n",
      "Epoch 6 train/test accuracy: 1.00/1.00\n",
      "Epoch 7 train/test accuracy: 1.00/1.00\n",
      "Epoch 8 train/test accuracy: 1.00/1.00\n",
      "Epoch 9 train/test accuracy: 1.00/1.00\n",
      "Epoch 10 train/test accuracy: 1.00/1.00\n",
      "Training on 1\n",
      "12089 4157\n",
      "Epoch 1 train/test accuracy: 0.91/0.59\n",
      "Epoch 2 train/test accuracy: 0.97/0.55\n",
      "Epoch 3 train/test accuracy: 0.98/0.53\n",
      "Epoch 4 train/test accuracy: 0.98/0.52\n",
      "Epoch 5 train/test accuracy: 0.98/0.51\n",
      "Epoch 6 train/test accuracy: 0.98/0.51\n",
      "Epoch 7 train/test accuracy: 0.98/0.51\n",
      "Epoch 8 train/test accuracy: 0.98/0.51\n",
      "Epoch 9 train/test accuracy: 0.98/0.50\n",
      "Epoch 10 train/test accuracy: 0.99/0.50\n",
      "Training on 2\n",
      "11263 6031\n",
      "Epoch 1 train/test accuracy: 0.04/0.58\n",
      "Epoch 2 train/test accuracy: 0.54/0.70\n",
      "Epoch 3 train/test accuracy: 0.84/0.66\n",
      "Epoch 4 train/test accuracy: 0.90/0.61\n",
      "Epoch 5 train/test accuracy: 0.92/0.58\n",
      "Epoch 6 train/test accuracy: 0.93/0.55\n",
      "Epoch 7 train/test accuracy: 0.94/0.53\n",
      "Epoch 8 train/test accuracy: 0.94/0.52\n",
      "Epoch 9 train/test accuracy: 0.95/0.50\n",
      "Epoch 10 train/test accuracy: 0.95/0.49\n",
      "Training on 3\n",
      "12183 8017\n",
      "Epoch 1 train/test accuracy: 0.00/0.39\n",
      "Epoch 2 train/test accuracy: 0.00/0.40\n",
      "Epoch 3 train/test accuracy: 0.00/0.41\n",
      "Epoch 4 train/test accuracy: 0.00/0.41\n",
      "Epoch 5 train/test accuracy: 0.00/0.42\n",
      "Epoch 6 train/test accuracy: 0.00/0.42\n",
      "Epoch 7 train/test accuracy: 0.00/0.42\n",
      "Epoch 8 train/test accuracy: 0.00/0.42\n",
      "Epoch 9 train/test accuracy: 0.00/0.42\n",
      "Epoch 10 train/test accuracy: 0.00/0.43\n",
      "Training on 4\n",
      "11800 10000\n",
      "Epoch 1 train/test accuracy: 0.00/0.34\n",
      "Epoch 2 train/test accuracy: 0.00/0.35\n",
      "Epoch 3 train/test accuracy: 0.00/0.35\n",
      "Epoch 4 train/test accuracy: 0.00/0.35\n",
      "Epoch 5 train/test accuracy: 0.00/0.35\n",
      "Epoch 6 train/test accuracy: 0.00/0.35\n",
      "Epoch 7 train/test accuracy: 0.00/0.35\n",
      "Epoch 8 train/test accuracy: 0.00/0.35\n",
      "Epoch 9 train/test accuracy: 0.00/0.35\n",
      "Epoch 10 train/test accuracy: 0.00/0.35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the KAN\n",
    "performance = []\n",
    "for task in range(len(tasks)):\n",
    "    print(f\"Training on {task}\")\n",
    "\n",
    "    # Create dataloader with the splitted training and testing sets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        splitted_train[task],\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Accumulate testing samples into performance array to evaluate forgetting of previous tasks\n",
    "    performance.extend(splitted_test[task])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        performance, \n",
    "        batch_size=batch_size_test, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # # Visualise a random image to check if the data is loaded correctly\n",
    "    # rand_image = random.choice(performance)\n",
    "    # print(rand_image[0][0].shape)\n",
    "    # plt.imshow(rand_image[0][0].numpy().reshape(28,28))\n",
    "    # plt.show()\n",
    "    \n",
    "    print(len(train_loader.dataset), len(test_loader.dataset))\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                test_loss += loss_fn(output, target).item() * data.size(0)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_acc = correct / len(test_loader.dataset)\n",
    "\n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1} train/test accuracy: {train_acc:.2f}/{test_acc:.2f}')\n",
    "\n",
    "    # Use evaluation plugin to evaluate the model\n",
    "    \n",
    "\n",
    "torch.save(model.state_dict(), \"mnist_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c430a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastKAN(\n",
       "  (layers): ModuleList(\n",
       "    (0): FastKANLayer(\n",
       "      (layernorm): LayerNorm((784,), eps=1e-05, elementwise_affine=True)\n",
       "      (rbf): RadialBasisFunction()\n",
       "      (spline_linear): SplineLinear(in_features=6272, out_features=64, bias=False)\n",
       "      (base_linear): Linear(in_features=784, out_features=64, bias=True)\n",
       "    )\n",
       "    (1): FastKANLayer(\n",
       "      (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (rbf): RadialBasisFunction()\n",
       "      (spline_linear): SplineLinear(in_features=512, out_features=10, bias=False)\n",
       "      (base_linear): Linear(in_features=64, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FastKAN(layers_hidden=[28*28,64,10], grid_min=3, grid_max=5, device=device)\n",
    "model.load_state_dict(torch.load(\"mnist_model.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e28078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Layer  FastKAN(\n",
      "  (layers): ModuleList(\n",
      "    (0): FastKANLayer(\n",
      "      (layernorm): LayerNorm((784,), eps=1e-05, elementwise_affine=True)\n",
      "      (rbf): RadialBasisFunction()\n",
      "      (spline_linear): SplineLinear(in_features=6272, out_features=64, bias=False)\n",
      "      (base_linear): Linear(in_features=784, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): FastKANLayer(\n",
      "      (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (rbf): RadialBasisFunction()\n",
      "      (spline_linear): SplineLinear(in_features=512, out_features=10, bias=False)\n",
      "      (base_linear): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "====> Layer  ModuleList(\n",
      "  (0): FastKANLayer(\n",
      "    (layernorm): LayerNorm((784,), eps=1e-05, elementwise_affine=True)\n",
      "    (rbf): RadialBasisFunction()\n",
      "    (spline_linear): SplineLinear(in_features=6272, out_features=64, bias=False)\n",
      "    (base_linear): Linear(in_features=784, out_features=64, bias=True)\n",
      "  )\n",
      "  (1): FastKANLayer(\n",
      "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (rbf): RadialBasisFunction()\n",
      "    (spline_linear): SplineLinear(in_features=512, out_features=10, bias=False)\n",
      "    (base_linear): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "====> Layer  FastKANLayer(\n",
      "  (layernorm): LayerNorm((784,), eps=1e-05, elementwise_affine=True)\n",
      "  (rbf): RadialBasisFunction()\n",
      "  (spline_linear): SplineLinear(in_features=6272, out_features=64, bias=False)\n",
      "  (base_linear): Linear(in_features=784, out_features=64, bias=True)\n",
      ")\n",
      "====> Layer  LayerNorm((784,), eps=1e-05, elementwise_affine=True)\n",
      "====> Layer  RadialBasisFunction()\n",
      "====> Layer  SplineLinear(in_features=6272, out_features=64, bias=False)\n",
      "====> Layer  Linear(in_features=784, out_features=64, bias=True)\n",
      "====> Layer  FastKANLayer(\n",
      "  (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (rbf): RadialBasisFunction()\n",
      "  (spline_linear): SplineLinear(in_features=512, out_features=10, bias=False)\n",
      "  (base_linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "====> Layer  LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "====> Layer  RadialBasisFunction()\n",
      "====> Layer  SplineLinear(in_features=512, out_features=10, bias=False)\n",
      "====> Layer  Linear(in_features=64, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "for layer in model.modules():\n",
    "    layers.append(layer)\n",
    "    print(\"====> Layer \", layer)\n",
    "layer = layers[1]\n",
    "# # for i in range(layer.input_dim):\n",
    "# for j in range(layer.output_dim):\n",
    "#     # layer.set_curve(i, j, torch.tensor([0.0, 1.0, 0.0], device=device))\n",
    "#     x, y = layer.plot_curve(0, j, num_pts=100, num_extrapolate_bins=3)\n",
    "#     plt.plot(x.to('cpu').numpy(), y.to('cpu').numpy(), label=f\"Last Layer, Input 0, Output {j}\")\n",
    "# # plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431db2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FastKANLayer' object has no attribute 'curve'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(black_image)\n\u001b[1;32m      5\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurve\u001b[49m(output, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/University/Thesis/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FastKANLayer' object has no attribute 'curve'"
     ]
    }
   ],
   "source": [
    "# for each pixel of the given input image, given a layer an input and an output, give me the gradient of the weights\n",
    "def get_gradient(model, layer, input, output):\n",
    "    model.zero_grad()\n",
    "    output = model(input)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    loss = F.cross_entropy(output, output)\n",
    "    loss.backward()\n",
    "    return layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ee585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
