{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a1d7c2-e8bd-43c3-8849-24fadafcabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "lr = 1\n",
    "momentum = 0.7\n",
    "\n",
    "tasks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e533f2-fba9-4be9-a4e6-2484cbde2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ff1 = nn.Linear(28*28, 512)\n",
    "        self.ff2 = nn.Linear(512, 10)\n",
    "        self.log_softmax = F.log_softmax\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.ff1(x))\n",
    "        x = self.log_softmax(self.ff2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #For every batch make gradient zero\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #Compute the negative log likelihood\n",
    "        loss = F.nll_loss(output, target)\n",
    "        #Backprobagate the loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / len(train_loader.dataset)\n",
    "    return train_acc\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e69be73-93da-4577-99f1-53ba1a5976f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train/test accuracy: 94.48/96.91\n",
      "Epoch 2 train/test accuracy: 98.25/97.60\n",
      "Epoch 3 train/test accuracy: 99.11/97.93\n",
      "Epoch 4 train/test accuracy: 99.52/98.05\n",
      "Epoch 5 train/test accuracy: 99.75/98.18\n",
      "Epoch 6 train/test accuracy: 99.82/98.23\n",
      "Epoch 7 train/test accuracy: 99.88/98.30\n",
      "Epoch 8 train/test accuracy: 99.89/98.37\n",
      "Epoch 9 train/test accuracy: 99.92/98.41\n",
      "Epoch 10 train/test accuracy: 99.93/98.40\n"
     ]
    }
   ],
   "source": [
    "def first_test(model, device):\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.1307),(0.3081)),\n",
    "        T.Lambda(lambda x: torch.flatten(x))\n",
    "    ])\n",
    "    train_df = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_df = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_df, batch_size=batch_size_train)\n",
    "    test_loader = torch.utils.data.DataLoader(test_df, batch_size=batch_size_test)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=momentum)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train_acc = train(model, device, train_loader, optimizer)\n",
    "        test_loss, test_acc = test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1} train/test accuracy: {train_acc:.2f}/{test_acc:.2f}')\n",
    "\n",
    "model = NN().to(device)\n",
    "first_test(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7340f486-6bdc-4033-9d76-553a26472a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task(random_seed):\n",
    "    rnd = np.random.RandomState(random_seed)\n",
    "    idx_permute = torch.from_numpy(rnd.permutation(28*28))\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0,.1307),(0.3081)),\n",
    "        T.Lambda(lambda x: torch.flatten(x)[idx_permute])\n",
    "    ])\n",
    "\n",
    "    train_df = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_df = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def test_all(model, device, tasks):\n",
    "    accs = []\n",
    "    for j in range(len(tasks)):\n",
    "        [train_df, test_df] = tasks[j]\n",
    "        test_loader = torch.utils.data.DataLoader(test_df, batch_size=test_bs)\n",
    "        tets_loss, test_acc = test(model, device, test_loader)\n",
    "        accs.append(test_acc)\n",
    "        print(f'Test on task {j+1}: loss {test_loss:.4f}, accuracy {test_acc:.2f}')\n",
    "    return accs\n",
    "\n",
    "tasks = [generate_task(random_seed=i) for i in range(len(tasks))]\n",
    "# plt.imshow(tasks[0][0][0][0].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cc3e3e1-2cd8-4673-bff4-5923c0a9d4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e2c9ba-ac80-4415-8359-21a45e20701d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute 'help'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtasks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhelp\u001b[49m() \u001b[38;5;66;03m#Task 0, training set\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'help'"
     ]
    }
   ],
   "source": [
    "tasks[0][0].help() #Task 0, training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dff062-f435-4ade-8cb8-12b0b7968c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
